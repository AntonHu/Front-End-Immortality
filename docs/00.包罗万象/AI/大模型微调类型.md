# 大模型微调类型

## 预训练

从零开始训练一个模型，一般这个流程叫做预训练，这个过程的目的就是让模型掌握语言的通用规律，以及基本的语言理解能力。

目前我们市面上主流的大模型，比如 `ChatGPT、DeepDeek` 等等，都属于 “自回归模型”，而 “自回归模型” 的本质就是：**用过去的自己来预测未来的自己**。

## 监督微调

通过标注过的数据直接教模型做事，适合有明确目标的任务。最简单的，我们直接告诉模型输入对应的输出是什么就可以了。

### 指令微调

知名开源数据集 [**alpaca-zh**](https://huggingface.co/datasets/shibing624/alpaca-zh)

```json
// 参考数据
[
  {
    "instruction": "将这句英文翻译成法语",
    "input": "Hello, how are you?",
    "output": "Bonjour, comment ça va ?"
  },
  ...
]
```

指令微调常见的业务场景：

- **智能教育**：实现作业辅导、规划个性化学习路径、辅助语言学习。
- **智能办公**：可处理文档、邮件，进行日程管理。
- **智能翻译**：应用于专业领域翻译、特定场景翻译及多语言交互。
- **数据分析**：让模型根据分析需求指令，对数据进行准确解读和洞察。

### 对话微调

知名开源数据集 [**guanaco-sharegpt-style**](https://huggingface.co/datasets/philschmid/guanaco-sharegpt-style)

```json
// 参考数据
[
  {
    "dialogue": [
      {"role": "user", "content": "今天天气怎么样？"},
      {"role": "assistant", "content": "北京今日多云转晴，气温22℃，适合户外活动。"},
      {"role": "user", "content": "那适合去长城吗？"},
      {"role": "assistant", "content": "长城景区海拔较高，建议携带外套，注意防晒。"}
    ]
  },
  ...
]
```

对话微调常见的业务场景：

- **智能客服系统**：提升客服机器人在处理用户咨询时的对话能力，能够更准确地理解用户意图并提供解决方案。
- **聊天机器人**：让聊天机器人更自然地与用户进行多轮对话，提高用户体验。
- **语音助手**：优化语音助手在语音交互中的对话表现，使其更符合用户的期望。

### 领域适配

知名开源数据集 [**PubMedQA**](https://huggingface.co/datasets/qiaojin/PubMedQA)

```json
// 参考数据
[
  {
    "instruction": "分析患者的症状描述",
    "input": "55岁男性，持续性胸骨后疼痛3小时，含服硝酸甘油无效",
    "output": "可能诊断：急性心肌梗死（STEMI），建议立即行心电图检查及心肌酶谱检测",
    "domain": "医疗"
  },
  {
    "instruction": "解释法律条款",
    "input": "《民法典》第1032条",
    "output": "该条款规定自然人享有隐私权，任何组织或个人不得以刺探、侵扰、泄露、公开等方式侵害他人隐私权",
    "domain": "法律"
  },
  ...
]
```

领域适配典型的业务场景：

- **医疗领域适配**：用于病历分析、疾病诊断辅助、医疗文献检索等。
- **法律领域适配**：辅助法律文件分析、案例检索、合同审查等。
- **金融领域适配**：用于风险评估、市场分析报告生成、金融产品推荐等。

### 文本分类

知名开源数据集 [**imdb**](https://huggingface.co/datasets/stanfordnlp/imdb)

```json
// 参考数据
[
  {"text": "这款手机续航长达48小时，拍照效果惊艳", "label": "positive"},
  {"text": "系统频繁卡顿，客服响应速度慢", "label": "negative"},
  {"text": "量子计算机突破新型纠错码技术", "label": "science_news"},
  {"text": "央行宣布下调存款准备金率0.5个百分点", "label": "finance_news"}
]
```

文本分类微调的典型业务场景：

- **情感分析**：商品评论情感极性识别（正面/负面/中性）
- **内容审核**：检测违规内容（涉政/暴力/广告）
- **新闻分类**：自动归类至财经/科技/体育等栏目
- **意图识别**：用户query分类（咨询/投诉/比价）

### 模型推理微调

知名开源数据集 [**NuminaMath-CoT**](https://huggingface.co/datasets/AI-MO/NuminaMath-CoT)

```json
// 参考数据
[
  {
    "instruction": "解决数学应用题",
    "input": "小明买了3支铅笔，每支2元；又买了5本笔记本，每本比铅笔贵4元。总花费多少？",
    "chain_of_thought": [
      "铅笔单价：2元/支 → 3支总价：3×2=6元",
      "笔记本单价：2+4=6元/本 → 5本总价：5×6=30元",
      "合计花费：6+30=36元"
    ],
    "output": "总花费为36元"
  },
  ...
]
```

理模型微调的场景：

- **代码生成与调试**：推理模型能够理解复杂的编程问题，生成高效的代码解决方案，并辅助开发人员进行代码调试。
- **数学问题求解**：在数学建模、复杂计算和逻辑推理任务中，推理模型表现出色，能够提供详细的解题步骤和准确的答案。
- **复杂数据分析**：推理模型擅长处理需要多步骤推理和策略规划的复杂数据分析任务，帮助科学家和研究人员进行更深入的数据挖掘。
- **法律与金融分析**：在处理法律合同、金融协议等复杂文档时，推理模型能够提取关键条款，理解模糊信息，辅助决策。

### 知识蒸馏

知识蒸馏（`Knowledge Distillation`）是将复杂模型（教师模型）的知识迁移到轻量级模型（学生模型）的技术，通过优化学生模型使其输出接近教师模型的“软标签”，从而在保持性能的同时降低推理成本。

## 强化学习微调

强化学习微调是，通过人类来主动反馈优化模型生成质量的方法，引入奖励模型（`Reward Model`）评估生成结果的合理性，并通过强化学习策略（如 `PPO` 算法）调整模型参数，使生成内容更符合人类偏好。

知名开源数据集 [**rm-static**](https://huggingface.co/datasets/Dahoas/rm-static)

```json
// 参考数据
[
  {
    "input": "请推荐一部科幻电影",
    "output": "《星际穿越》是一部经典科幻片，探讨了时间与亲情。",
    "reward_score": 4.5  // 人类标注的质量评分（0-5分）
  },
  {
    "input": "解释黑洞理论",
    "output": "黑洞是由暗物质构成的神秘天体，会吞噬一切物质。",
    "reward_score": 2.0  // 包含错误信息，得分低
  }
]
```

强化学习微调的典型业务场景：

- **对话系统优化**：提升回复的相关性，对齐人类价值观（安全、无害、有用性）。
- **内容生成**：控制输出风格（如幽默、正式）或避免敏感信息。
- **代码生成**：优化代码的可读性和正确性。

## 多模态微调

强化学习微调是，通过人类来主动反馈优化模型生成质量的方法，引入奖励模型（`Reward Model`）评估生成结果的合理性，并通过强化学习策略（如 `PPO` 算法）调整模型参数，使生成内容更符合人类偏好。

知名开源数据集 [**the_cauldron**](https://huggingface.co/datasets/HuggingFaceM4/the_cauldron)

```json
// 参考数据
[
  {
    "text": "一只猫在追蝴蝶",
    "image_url": "https://example.com/cat.jpg",
    "caption": "一只橘色的猫正在追逐花园里的白色蝴蝶"
  },
  {
    "audio": "audio.wav",
    "text": "会议录音转写：今天的议题是...",
    "summary": "会议讨论了Q3销售目标与市场策略"
  }
]
```

多模态微调的典型业务场景：

- **图文问答**：输入图片和问题，生成答案。
- **视频内容理解**：分析视频帧和字幕，生成摘要。
- **跨模态检索**：根据文本描述搜索相关图像/视频。

